{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caiogasparine/3253-Machine-Learning/blob/main/W6_Assignment_SMV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5-9VIiXdAE9"
      },
      "source": [
        "## Assignment for Module 6\n",
        "\n",
        "In this assignment you will continue working with the housing price per district from the previous module assignment, this time training SVM models, both for regression and classification.\n",
        "\n",
        "#### Getting the data for the assignment (similar to the notebook from chapter 2 of Hands-On...)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUX7lsaJdAE_"
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "from six.moves import urllib\n",
        "\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
        "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
        "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
        "\n",
        "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
        "    if not os.path.isdir(housing_path):\n",
        "        os.makedirs(housing_path)\n",
        "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
        "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
        "    housing_tgz = tarfile.open(tgz_path)\n",
        "    housing_tgz.extractall(path=housing_path)\n",
        "    housing_tgz.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLKvLB8CdAFC"
      },
      "source": [
        "fetch_housing_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zUYMKrtdAFG"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_housing_data(housing_path=HOUSING_PATH):\n",
        "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
        "    return pd.read_csv(csv_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fq97xo5KdAFI"
      },
      "source": [
        "housing = load_housing_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdY0LGtrdAFK"
      },
      "source": [
        "### Fix the categories in the categorical variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_qMwbHWdAFL"
      },
      "source": [
        "d = {'<1H OCEAN':'LESS_1H_OCEAN', 'INLAND':'INLAND', 'ISLAND':'ISLAND', 'NEAR BAY':'NEAR_BAY', 'NEAR OCEAN':'NEAR_OCEAN'}\n",
        "housing['ocean_proximity'] = housing['ocean_proximity'].map(lambda s: d[s])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33IYdIH9dAFO"
      },
      "source": [
        "### Add 2 more features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyZvk3rmdAFO"
      },
      "source": [
        "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
        "housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPfHvDpadAFR"
      },
      "source": [
        "### Fix missing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7Dk4rradAFS"
      },
      "source": [
        "median = housing[\"total_bedrooms\"].median()\n",
        "housing[\"total_bedrooms\"].fillna(median, inplace=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUVtY2wkdAFX"
      },
      "source": [
        "### Create dummy variables based on the categorical variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9VLwS8SdAFY"
      },
      "source": [
        "one_hot = pd.get_dummies(housing['ocean_proximity'])\n",
        "housing = housing.drop('ocean_proximity', axis=1)\n",
        "housing = housing.join(one_hot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alffKG2-dAFc"
      },
      "source": [
        "### Check the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnlSlmRXdAFc",
        "outputId": "21e5e42a-4255-432c-a490-ba251b47b13f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "housing.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20640 entries, 0 to 20639\n",
            "Data columns (total 16 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   longitude                 20640 non-null  float64\n",
            " 1   latitude                  20640 non-null  float64\n",
            " 2   housing_median_age        20640 non-null  float64\n",
            " 3   total_rooms               20640 non-null  float64\n",
            " 4   total_bedrooms            20640 non-null  float64\n",
            " 5   population                20640 non-null  float64\n",
            " 6   households                20640 non-null  float64\n",
            " 7   median_income             20640 non-null  float64\n",
            " 8   median_house_value        20640 non-null  float64\n",
            " 9   rooms_per_household       20640 non-null  float64\n",
            " 10  population_per_household  20640 non-null  float64\n",
            " 11  INLAND                    20640 non-null  uint8  \n",
            " 12  ISLAND                    20640 non-null  uint8  \n",
            " 13  LESS_1H_OCEAN             20640 non-null  uint8  \n",
            " 14  NEAR_BAY                  20640 non-null  uint8  \n",
            " 15  NEAR_OCEAN                20640 non-null  uint8  \n",
            "dtypes: float64(11), uint8(5)\n",
            "memory usage: 1.8 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsf_FZO2dAFf"
      },
      "source": [
        "### Partition into train and test\n",
        "\n",
        "Use train_test_split from sklearn.model_selection to partition the dataset into 70% for training and 30% for testing.\n",
        "\n",
        "You can use the 70% for training set as both training and validation by using cross-validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guqUiBbJdAFf"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_set, test_set = train_test_split(housing, test_size=0.3, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSrY7s0udAFh"
      },
      "source": [
        "### Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AU8E3XPBdAFi"
      },
      "source": [
        "target = 'median_house_value'\n",
        "features = list(train_set.columns)\n",
        "features = [f for f in features if f!=target]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWohQ7yYdAFk"
      },
      "source": [
        "X_tr = train_set[features]\n",
        "y_tr = train_set[[target]]\n",
        "\n",
        "X_te = test_set[features]\n",
        "y_te = test_set[[target]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvdwozbHdAFn"
      },
      "source": [
        "### Scaling features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa2QmyXEdAFn"
      },
      "source": [
        "Similarly, use StandardScaler from sklearn.preprocessing to normalize the training and testing data, using the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpY8N4EsdAFo"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_tr)\n",
        "X_tr = scaler.transform(X_tr)\n",
        "X_te = scaler.transform(X_te)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHbNOg48dAFq"
      },
      "source": [
        "#### Comparing models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1QkbAf4dAFr"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np\n",
        "\n",
        "def display_scores(scores):\n",
        "    print(\"Scores:\", scores)\n",
        "    print(\"Mean:\", scores.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNb5s58GdAFu"
      },
      "source": [
        "### Linear regression on original features (no transformations) --- benchmark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vkcq4QmxdAFw",
        "outputId": "010339c6-22c6-4a90-9103-66ee5f658bf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "lin_scores = cross_val_score(LinearRegression(), train_set[features], train_set[target], scoring=\"neg_mean_squared_error\", cv=4)\n",
        "lin_rmse_scores = np.sqrt(-lin_scores)\n",
        "display_scores(lin_rmse_scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scores: [70142.55721218 67456.39127204 67318.3258893  70866.26065275]\n",
            "Mean: 68945.88375656855\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EZ-i_o5dAFy"
      },
      "source": [
        "### 1. Support Vector Machines for Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krGzlqsVdAFz"
      },
      "source": [
        "#### (a) In this exercise your goal is to tune SVR with FBR kernel, and make the average score mean_squared_error over 3-folds (cv=3) below 58000. \n",
        "\n",
        "You are encouraged to try optimizing any of the hyper-parameters of SVR\n",
        "\n",
        "See http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html for more details\n",
        "\n",
        "However, as a hint, you can focus on C and gamma. \n",
        "\n",
        "Hint 2: if when you try different values for a hyper-parameter, the optimal models corresponds to one of the extreme values in your range, that probably means you can keep improving your solution by considering values beyond the current range.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tv9BM1SdAF0"
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "C_vals = [] ## YOUR VALUES FOR C ##\n",
        "gamma_vals = [] ## YOUR VALUES FOR gamma ## \n",
        "\n",
        "param_grid = [{'C':C_vals, 'gamma':gamma_vals}]\n",
        "grid_search_rbf = GridSearchCV(SVR(kernel='rbf'), param_grid, cv=3,scoring='neg_mean_squared_error')\n",
        "grid_search_rbf.fit(X_tr, np.ravel(y_tr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSgRWjFKdAF3"
      },
      "source": [
        "print(grid_search_rbf.best_params_)\n",
        "print(np.sqrt(-grid_search_rbf.best_score_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Vd7QcjwdAF5"
      },
      "source": [
        "### Performance on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHMMV0zAdAF6"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "final_model = grid_search_rbf.best_estimator_   ## THIS SHOULD BE THE BEST GRID_SEARCH ##\n",
        "\n",
        "y_te_estimation = final_model.predict(X_te)\n",
        "\n",
        "final_mse = mean_squared_error(y_te, y_te_estimation)\n",
        "final_rmse = np.sqrt(final_mse)\n",
        "print(final_rmse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsWtf0jVdAF8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(x=y_te, y=y_te_estimation)\n",
        "plt.xlim([-200000,800000])\n",
        "plt.ylim([-200000,800000])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "lJ2esFA_dAF-"
      },
      "source": [
        "### 2. SVM for Classification\n",
        "\n",
        "Now we transform the continuous target into a binary variable, indicating whether or not the price is above the average $179700\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yT0m7tFdAF_"
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRTpdER3dAGC",
        "outputId": "63c56529-4744-44e0-9375-838bcd6dab3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.median(housing[['median_house_value']])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "179700.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsFmixErdAGE"
      },
      "source": [
        "#### Binary target variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmC6FSFndAGF"
      },
      "source": [
        "y_tr_b = 1*np.ravel(y_tr>=179700.0)\n",
        "y_te_b = 1*np.ravel(y_te>=179700.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piEb-eU8dAGH"
      },
      "source": [
        "#### Linear SVM for classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-b4cZiQPdAGI"
      },
      "source": [
        "from sklearn.svm import LinearSVC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w19jYJcNdAGK",
        "outputId": "95b7812a-287e-4942-dc36-44e14b085eda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "lin_clf = LinearSVC(random_state=42)\n",
        "lin_clf.fit(X_tr, y_tr_b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "          multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
              "          verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb0OgLLIdAGO",
        "outputId": "80eed996-ff40-4efe-fc30-386e7fe62046",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred = lin_clf.predict(X_te)\n",
        "accuracy_score(y_te_b, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8389857881136951"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLxBwmSqdAGQ"
      },
      "source": [
        "### (a) Does SVC (with default hyper-parameters) improve the performance of the linear SVM?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKF4C2VxdAGR"
      },
      "source": [
        "from sklearn.svm import SVC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZtTBhFndAGT",
        "outputId": "7fc80248-bccd-4fb3-f3f9-0ca941f8c1df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## YOUR CODE HERE ##\n",
        "## YOUR CODE HERE ##\n",
        "## YOUR CODE HERE ##\n",
        "## YOUR CODE HERE ##\n",
        "lin_clf = SVC(random_state=42)\n",
        "lin_clf.fit(X_tr, y_tr_b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=42, shrinking=True, tol=0.001,\n",
              "    verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwGKuMXWEUI0",
        "outputId": "8e689f35-31a2-446e-f783-8b0fec7e02b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred = lin_clf.predict(X_tr)\n",
        "accuracy_score(y_tr_b, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.866140642303433"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijEJ5_aTdAGV"
      },
      "source": [
        "### (b) Use randomized search to tune hyper-parameters of SVC and improve its performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpVzS-HZdAGW"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import reciprocal, uniform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ADkR3C6dAGY"
      },
      "source": [
        "## YOUR CODE HERE ##\n",
        "## YOUR CODE HERE ##\n",
        "## YOUR CODE HERE ##\n",
        "## YOUR CODE HERE ##\n",
        "## YOUR CODE HERE ##\n",
        "## YOUR CODE HERE ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpjtvchVdAGi"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}